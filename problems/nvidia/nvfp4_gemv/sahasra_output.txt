Running on:
GPU: NVIDIA B200
CPU: INTEL(R) XEON(R) PLATINUM 8570
Runtime: CUDA
Platform: Linux-6.8.0-51-generic-x86_64-with-glibc2.35
Torch: 2.9.1+cu130
Running failed
Command
python3 eval.py benchmark /tmp/tmpkugtsua8

exited with error code 1 after 33.34 seconds.
Cluster Bot
APP
 — 5:45 PM
Program stderr (1/1):
multiprocessing.pool.RemoteTraceback:
"""
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/runner/_work/discord-cluster-manager/discord-cluster-manager/eval.py", line 217, in _run_single_benchmark
    output = custom_kernel(_clone_data(data))
  File "/home/runner/_work/discord-cluster-manager/discord-cluster-manager/submission.py", line 1600, in custom_kernel
    mod.launch_fp4_gemv_optimized(a_bytes, b_bytes, sfa_bytes, sfb_bytes, c, M, K, L)
RuntimeError: CUDA error: unspecified launch failure
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/runner/_work/discord-cluster-manager/discord-cluster-manager/eval.py", line 485, in <module>
    sys.exit(main())
  File "/home/runner/_work/discord-cluster-manager/discord-cluster-manager/eval.py", line 453, in main
    return run_benchmarking(logger, pool, tests)
  File "/home/runner/_work/discord-cluster-manager/discord-cluster-manager/eval.py", line 306, in run_benchmarking
    run_single_benchmark(pool, tests[0], False, 200, 10e7)
  File "/home/runner/_work/discord-cluster-manager/discord-cluster-manager/eval.py", line 291, in run_single_benchmark
    return pool.apply(_run_single_benchmark, (test, recheck, max_repeats, max_time_ns))
  File "/usr/lib/python3.10/multiprocessing/pool.py", line 360, in apply
    return self.apply_async(func, args, kwds).get()
  File "/usr/lib/python3.10/multiprocessing/pool.py", line 774, in get
    raise self._value
RuntimeError: CUDA error: unspecified launch failure
Program stdout (1/6):
[SCALE DEBUG] sfa_ref_cpu shape=torch.Size([7168, 1024, 1]), device=cuda:0
[SCALE DEBUG] sfb_ref_cpu shape=torch.Size([128, 1024, 1]), device=cuda:0
[DEBUG] a_bytes: shape=(1, 7168, 8192), stride=(58720256, 8192, 1), elem_size=1, numel=58720256, bytes=58720256, data_ptr=0x7ffc2a000000
[DEBUG] b_bytes: shape=(1, 128, 8192), stride=(1048576, 8192, 1), elem_size=1, numel=1048576, bytes=1048576, data_ptr=0x7ffc67800000
[DEBUG] sfa_bytes: shape=(1, 7168, 1024), stride=(7340032, 1024, 1), elem_size=1, numel=7340032, bytes=7340032, data_ptr=0x7ffc30000000
[DEBUG] sfb_bytes: shape=(1, 128, 1024), stride=(131072, 1024, 1), elem_size=1, numel=131072, bytes=131072, data_ptr=0x7ffc63bce000
[DEBUG] a_bytes range: [0x7ffc2a000000, 0x7ffc2d800000) (58720256 bytes)
[DEBUG] b_bytes range: [0x7ffc67800000, 0x7ffc67900000) (1048576 bytes)
[DEBUG] sfa_bytes range: [0x7ffc30000000, 0x7ffc30700000) (7340032 bytes)
[DEBUG] sfb_bytes range: [0x7ffc63bce000, 0x7ffc63bee000) (131072 bytes)
[DEBUG] a shape=(1, 7168, 8192), stride=(58720256, 8192, 1), data_ptr=0x7ffc2a000000
[DEBUG] b shape=(1, 128, 8192), stride=(1048576, 8192, 1), data_ptr=0x7ffc67800000
✅(Python) a_bytes 128-byte alignment check passed: 0x7ffc2a000000
✅(Python) b_bytes 128-byte alignment check passed: 0x7ffc67800000
Program stdout (2/6):
[1/2] /usr/local/cuda-13.0/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=nvfp4_gemv_sm100_ptx -DTORCH_API_INCLUDE_EXTENSION_H -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda-13.0/include -isystem /usr/include/python3.10 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -gencode=arch=compute_100a,code=sm_100a --expt-relaxed-constexpr --expt-extended-lambda -Xcudafe --diag_suppress=20012 -maxrregcount=128 --ptxas-options=-v,-warn-lmem-usage -lineinfo -I/usr/local/cutlass/include -c /home/runner/.cache/torch_extensions/py310_cu130/nvfp4_gemv_sm100_ptx/cuda.cu -o cuda.cuda.o
/home/runner/.cache/torch_extensions/py310_cu130/nvfp4_gemv_sm100_ptx/cuda.cu(959): warning #177-D: variable "kTileScaleCount" was declared but never referenced
      constexpr int kTileScaleCount = kTileK / 16;
                    ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/home/runner/.cache/torch_extensions/py310_cu130/nvfp4_gemv_sm100_ptx/cuda.cu(1019): warning #177-D: variable "use_tma_a" was declared but never referenced
      bool use_tma_a = true;
           ^

/home/runner/.cache/torch_extensions/py310_cu130/nvfp4_gemv_sm100_ptx/cuda.cu(743): warning #177-D: variable "nmblocks_sfa" was declared but never referenced
              int nmblocks_sfa = (M + 127) / 128;
                  ^

/home/runner/.cache/torch_extensions/py310_cu130/nvfp4_gemv_sm100_ptx/cuda.cu(744): warning #177-D: variable "nkblocks_sfa" was declared but never referenced
              int nkblocks_sfa = (K_scales + 3) / 4;
                  ^
Program stdout (3/6):
/home/runner/.cache/torch_extensions/py310_cu130/nvfp4_gemv_sm100_ptx/cuda.cu(228): warning #177-D: variable "TileScaleCount" was declared but never referenced
      constexpr int TileScaleCount = TileK / 16;
                    ^

/home/runner/.cache/torch_extensions/py310_cu130/nvfp4_gemv_sm100_ptx/cuda.cu(232): warning #177-D: variable "ProducerThreads" was declared but never referenced
      constexpr int ProducerThreads = 64;
                    ^

ptxas warning : Local memory used for function '_Z18fp4_gemv_streamingILi128ELi128ELi320EEvPKhS1_S1_S1_PK14CUtensorMap_stS4_S4_S4_P6__halfiii', size of stack frame: 128 bytes
ptxas info    : 6057 bytes gmem
ptxas info    : Compiling entry function '_Z18fp4_gemv_streamingILi128ELi128ELi320EEvPKhS1_S1_S1_PK14CUtensorMap_stS4_S4_S4_P6__halfiii' for 'sm_100a'
ptxas info    : Function properties for _Z18fp4_gemv_streamingILi128ELi128ELi320EEvPKhS1_S1_S1_PK14CUtensorMap_stS4_S4_S4_P6__halfiii
    128 bytes stack frame, 24 bytes spill stores, 24 bytes spill loads
ptxas info    : Used 48 registers, used 1 barriers, 128 bytes cumulative stack size, 16 bytes smem
ptxas info    : Compile time = 116.141 ms
[2/2] c++ main.o cuda.cuda.o -shared -lcuda -L/usr/local/lib/python3.10/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda-13.0/lib64 -lcudart -o nvfp4_gemv_sm100_ptx.so
✅A_ptr 128-byte alignment check passed: 0x7ffc2a000000
✅K_packed 128-byte stride alignment check passed: 8192 bytes
TMA Debug: A_ptr = 0x7ffc2a000000, map_A_ptr = 0x55556238ed00
WARNING: box_k (64) is not a multiple of 128 elements, may reduce TMA efficiency
✅Tile size 128-byte alignment check passed: 8192 bytes
TMA Debug: Using RANK=2 for L=1
TMA Debug: dims = [K_packed=8192, M=7168], box = [64, 128]
TMA Debug: strides_A[0] = 8192 bytes
TMA Encode A Result: 0
✅TMA Encode A (rank=2) SUCCESS!
Program stdout (4/6):
✅TMA Encode B (rank=2) SUCCESS!
✅TMA Encode SFB (rank=2) SUCCESS!
TMA SFA (rank=2): dims=[1024,7168] box=[16,128] stride=[1024] ptr=0x7ffc30000000
✅TMA Encode SFA (rank=2) SUCCESS!
DEBUG launch grid=(56,1) blockDim.x=320 shared_bytes=109696 M=7168 K=16384 L=1
=== KERNEL DEBUG (block 0,0) ===
DBG block=(51,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=6528 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(50,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=6400 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(55,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=7040 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(54,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=6912 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(44,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=5632 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(45,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=5760 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(27,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=3456 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(26,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=3328 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(28,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=3584 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(49,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=6272 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(29,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=3712 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(48,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=6144 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
Program stdout (5/6):
DBG block=(30,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=3840 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(38,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=4864 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(31,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=3968 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(39,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=4992 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(36,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=4608 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(37,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=4736 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(41,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=5248 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(40,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=5120 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(43,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=5504 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(42,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=5376 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(21,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=2688 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(20,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=2560 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(25,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=3200 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(24,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=3072 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(32,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=4096 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
Program stdout (6/6):
DBG block=(14,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=1792 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(15,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=1920 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(19,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=2432 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(18,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=2304 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
DBG block=(17,0,0) tid=0 warp_id=0 lane_id=0 batch=0 m_tile=2176 tile_rows=128 M=7168 K=16384 L=1 K_packed=8192 K_scales=1024
SFB raw bytes [0-3]: 0x40 0x38 0x38 0x00
SFB decoded FP8 [0-3]: 2.000000 1.000000 1.000000 0.000000
B packed bytes [0-3]: 0x03 0x01 0x01 0x00
SFB contiguous_idx[row=0,col=0,batch=0] = 0
SFB contiguous_idx[row=0,col=1,batch=0] = 1
SFB contiguous_idx[row=0,col=2,batch=0] = 2
