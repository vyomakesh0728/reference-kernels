For help, type "help".
Type "apropos word" to search for commands related to "word".
(cuda-gdb) target cudacore /tmp/cuda_coredump_imaginary-amaranth-oriole.5717.1765893865
Opening GPU coredump: /tmp/cuda_coredump_imaginary-amaranth-oriole.5717.1765893865
[Current focus set to CUDA kernel 0, grid 49, block (0,0,0), thread (64,0,0), device 0, sm 142, warp 0, lane 0]
#0  0x00007fef8da015c0 in fp4_gemm_rank2_cta<128, 256, 128><<<(1,2,1),(128,1,1)>>> () at /root/.cache/torch_extensions/py310_cu130/nvfp4_gemm_sm100_ptx/cuda.cu:1184
1184	    uint32_t tmem_c = tmem_base_ptr_tcgen05;
(cuda-gdb) where
#0  0x00007fef8da015c0 in fp4_gemm_rank2_cta<128, 256, 128><<<(1,2,1),(128,1,1)>>> () at /root/.cache/torch_extensions/py310_cu130/nvfp4_gemm_sm100_ptx/cuda.cu:1184
(cuda-gdb) list
1179	            "tcgen05.alloc.cta_group::1.sync.aligned.shared::cta.b32 [%0], %1;\n"
1180	            :
1181	            : "r"(dst_smem), "r"(num_cols));
1182	    }
1183	    __syncthreads();
1184	    uint32_t tmem_c = tmem_base_ptr_tcgen05;
1185	    
1186	    // TMEM addresses for scale factors (32b columns)
1187	    constexpr uint32_t ACC_COLS        = TileN;                          // 128 columns for FP32 values
1188	    constexpr uint32_t KScalesTile     = TileK / 16;                     // 16 FP8 scales per K-tile
(cuda-gdb) 